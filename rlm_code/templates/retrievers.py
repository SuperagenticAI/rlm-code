"""
DSPy Retriever Templates

This module provides templates for retriever integration including:
- ColBERTv2 retriever setup
- Custom retriever implementation
- RAG module templates with retriever integration
- Retriever configuration examples

Each template includes complete working code with examples.
"""

from dataclasses import dataclass


@dataclass
class RetrieverInfo:
    """Information about a retriever type."""

    name: str
    display_name: str
    description: str
    best_for: str
    requires: list
    difficulty: str
    keywords: list


class RetrieverTemplates:
    """Registry of DSPy retriever templates."""

    def __init__(self):
        self.retrievers = {
            "colbertv2": self._colbertv2_info(),
            "custom": self._custom_info(),
            "embeddings": self._embeddings_info(),
        }

    def list_all(self) -> list[RetrieverInfo]:
        """List all available retriever types."""
        return list(self.retrievers.values())

    def get_retriever_code(self, name: str, use_case: str = "rag") -> str | None:
        """Get complete code for a retriever."""
        generators = {
            "colbertv2": self._generate_colbertv2,
            "custom": self._generate_custom,
            "embeddings": self._generate_embeddings,
        }

        generator = generators.get(name)
        return generator(use_case) if generator else None

    def search(self, query: str) -> list[RetrieverInfo]:
        """Search retrievers by keywords."""
        query_lower = query.lower()
        matches = []

        for retriever in self.retrievers.values():
            if (
                any(kw in query_lower for kw in retriever.keywords)
                or query_lower in retriever.best_for.lower()
            ):
                matches.append(retriever)

        return matches

    # Retriever Info Methods

    def _colbertv2_info(self) -> RetrieverInfo:
        return RetrieverInfo(
            name="colbertv2",
            display_name="ColBERTv2",
            description="State-of-the-art neural retrieval model for semantic search",
            best_for="Production RAG systems, high-quality retrieval, semantic search",
            requires=["ColBERTv2 server", "Indexed documents"],
            difficulty="intermediate",
            keywords=["colbert", "colbertv2", "semantic", "neural", "production"],
        )

    def _custom_info(self) -> RetrieverInfo:
        return RetrieverInfo(
            name="custom",
            display_name="Custom Retriever",
            description="Build your own retriever implementation",
            best_for="Custom retrieval logic, domain-specific search, prototyping",
            requires=["Custom retrieval logic", "Document indexing"],
            difficulty="advanced",
            keywords=["custom", "implementation", "domain-specific", "prototype"],
        )

    def _embeddings_info(self) -> RetrieverInfo:
        return RetrieverInfo(
            name="embeddings",
            display_name="Embeddings Retriever",
            description="Vector-based retrieval using embeddings",
            best_for="Vector databases, embedding-based search, FAISS/Chroma",
            requires=["Embedding model", "Vector database"],
            difficulty="intermediate",
            keywords=["embeddings", "vector", "faiss", "chroma", "pinecone"],
        )

    # Template Generation Methods

    def _generate_colbertv2(self, use_case: str = "rag") -> str:
        """Generate ColBERTv2 retriever template."""
        return '''"""
ColBERTv2 Retriever Integration

ColBERTv2 is a state-of-the-art neural retrieval model that provides
high-quality semantic search for RAG applications.

Generated by RLM Code - Retriever Template
"""

import dspy

# ============================================================================
# 1. CONFIGURE ColBERTv2 RETRIEVER
# ============================================================================

# Option 1: Use public ColBERTv2 server
colbertv2_retriever = dspy.ColBERTv2(
    url='http://20.102.90.50:2017/wiki17_abstracts'  # Public server
)

# Option 2: Use your own ColBERTv2 server
# colbertv2_retriever = dspy.ColBERTv2(
#     url='http://localhost:8893/api/search'  # Your server
# )

# Configure DSPy to use ColBERTv2
dspy.configure(rm=colbertv2_retriever)

print("✓ Configured ColBERTv2 retriever")

# ============================================================================
# 2. CREATE RETRIEVER MODULE
# ============================================================================

# Create a retriever that fetches top-k passages
retriever = dspy.Retrieve(k=5)  # Retrieve top 5 passages

# Test retrieval
query = "What is machine learning?"
results = retriever(query)

print(f"\\nQuery: {query}")
print(f"Retrieved {len(results.passages)} passages:")
for i, passage in enumerate(results.passages[:3], 1):
    print(f"  {i}. {passage[:100]}...")

# ============================================================================
# 3. RAG MODULE WITH ColBERTv2
# ============================================================================

class RAGSignature(dspy.Signature):
    """Answer questions using retrieved context."""
    context = dspy.InputField(desc="Retrieved context passages")
    question = dspy.InputField(desc="User's question")
    answer = dspy.OutputField(desc="Answer based on context")


class RAGModule(dspy.Module):
    """RAG system using ColBERTv2 for retrieval."""

    def __init__(self, k=5):
        super().__init__()
        self.retrieve = dspy.Retrieve(k=k)
        self.generate = dspy.ChainOfThought(RAGSignature)

    def forward(self, question: str):
        # Retrieve relevant passages
        retrieved = self.retrieve(question)
        context = "\\n\\n".join(retrieved.passages)

        # Generate answer from context
        result = self.generate(context=context, question=question)
        return result


# ============================================================================
# 4. USAGE EXAMPLE
# ============================================================================

def main():
    """Example usage of ColBERTv2 RAG system."""

    # Create RAG module
    rag = RAGModule(k=5)

    # Example questions
    questions = [
        "What is quantum computing?",
        "How does neural networks work?",
        "What is the theory of relativity?",
    ]

    print("\\n" + "="*70)
    print("ColBERTv2 RAG System")
    print("="*70 + "\\n")

    for question in questions:
        print(f"Q: {question}")
        result = rag(question=question)
        print(f"A: {result.answer}")
        print("-" * 70)


# ============================================================================
# 5. SETTING UP YOUR OWN ColBERTv2 SERVER
# ============================================================================

"""
To set up your own ColBERTv2 server:

1. Install ColBERTv2:
   pip install colbert-ai

2. Index your documents:
   python -m colbert.index --documents your_docs.jsonl --index your_index

3. Start the server:
   python -m colbert.serve --index your_index --port 8893

4. Use in DSPy:
   colbertv2_retriever = dspy.ColBERTv2(url='http://localhost:8893/api/search')
   dspy.configure(rm=colbertv2_retriever)
"""


# ============================================================================
# 6. BENEFITS OF ColBERTv2
# ============================================================================

"""
Benefits:
- State-of-the-art retrieval quality
- Semantic understanding (not just keyword matching)
- Fast retrieval with pre-computed indexes
- Production-ready and scalable
- Better than simple keyword search
"""

if __name__ == "__main__":
    main()
'''

    def _generate_custom(self, use_case: str = "rag") -> str:
        """Generate custom retriever template."""
        return '''"""
Custom Retriever Implementation

Build your own retriever for domain-specific retrieval needs.

Generated by RLM Code - Retriever Template
"""

import dspy
from typing import List, Dict, Any
from abc import ABC, abstractmethod


# ============================================================================
# 1. CUSTOM RETRIEVER INTERFACE
# ============================================================================

class CustomRetriever(ABC):
    """Base class for custom retrievers."""

    @abstractmethod
    def __call__(self, query: str, k: int = 5) -> List[Dict[str, Any]]:
        """Retrieve documents for a query.

        Args:
            query: Search query
            k: Number of documents to retrieve

        Returns:
            List of documents with 'text' and optional metadata
        """
        pass


# ============================================================================
# 2. EXAMPLE: KEYWORD-BASED RETRIEVER
# ============================================================================

class KeywordRetriever(CustomRetriever):
    """Simple keyword-based retriever."""

    def __init__(self, documents: List[Dict[str, Any]]):
        """
        Initialize with documents.

        Args:
            documents: List of dicts with 'text' and optional metadata
        """
        self.documents = documents

    def __call__(self, query: str, k: int = 5) -> List[Dict[str, Any]]:
        """Retrieve documents based on keyword matching."""
        query_words = set(query.lower().split())

        # Score documents by keyword overlap
        scored_docs = []
        for doc in self.documents:
            doc_text = doc.get('text', '').lower()
            doc_words = set(doc_text.split())
            score = len(query_words & doc_words)

            if score > 0:
                scored_docs.append((score, doc))

        # Sort by score and return top k
        scored_docs.sort(reverse=True, key=lambda x: x[0])
        return [doc for _, doc in scored_docs[:k]]


# ============================================================================
# 3. EXAMPLE: SEMANTIC RETRIEVER (using embeddings)
# ============================================================================

class SemanticRetriever(CustomRetriever):
    """Semantic retriever using embeddings."""

    def __init__(self, documents: List[Dict[str, Any]], embedding_model=None):
        """
        Initialize with documents and embedding model.

        Args:
            documents: List of document dicts
            embedding_model: Embedding model (e.g., sentence-transformers)
        """
        self.documents = documents

        # Use DSPy's embedding model if available
        if embedding_model is None:
            try:
                from dspy.retrievers import Embeddings
                self.embedding_model = Embeddings()
            except:
                self.embedding_model = None
        else:
            self.embedding_model = embedding_model

        # Pre-compute document embeddings
        self.doc_embeddings = self._embed_documents()

    def _embed_documents(self) -> List[List[float]]:
        """Pre-compute embeddings for all documents."""
        if self.embedding_model is None:
            return []

        embeddings = []
        for doc in self.documents:
            text = doc.get('text', '')
            embedding = self.embedding_model(text)
            embeddings.append(embedding)

        return embeddings

    def __call__(self, query: str, k: int = 5) -> List[Dict[str, Any]]:
        """Retrieve documents using semantic similarity."""
        if self.embedding_model is None:
            # Fallback to keyword matching
            return KeywordRetriever(self.documents)(query, k)

        # Embed query
        query_embedding = self.embedding_model(query)

        # Compute similarity scores
        import numpy as np
        scores = []
        for i, doc_emb in enumerate(self.doc_embeddings):
            similarity = np.dot(query_embedding, doc_emb) / (
                np.linalg.norm(query_embedding) * np.linalg.norm(doc_emb)
            )
            scores.append((similarity, self.documents[i]))

        # Sort by similarity and return top k
        scores.sort(reverse=True, key=lambda x: x[0])
        return [doc for _, doc in scores[:k]]


# ============================================================================
# 4. WRAPPER FOR DSPy
# ============================================================================

class DSPyRetrieverWrapper:
    """Wrapper to use custom retriever with dspy.Retrieve."""

    def __init__(self, custom_retriever: CustomRetriever):
        self.custom_retriever = custom_retriever

    def __call__(self, query: str, k: int = 5):
        """Call custom retriever and return DSPy-compatible format."""
        results = self.custom_retriever(query, k)

        # Extract passages
        passages = [doc.get('text', '') for doc in results]

        # Return DSPy Prediction format
        from dspy.primitives.prediction import Prediction
        return Prediction(passages=passages)


# ============================================================================
# 5. RAG MODULE WITH CUSTOM RETRIEVER
# ============================================================================

class CustomRAGSignature(dspy.Signature):
    """Answer questions using custom retrieved context."""
    context = dspy.InputField(desc="Retrieved context")
    question = dspy.InputField(desc="User's question")
    answer = dspy.OutputField(desc="Answer based on context")


class CustomRAGModule(dspy.Module):
    """RAG system using custom retriever."""

    def __init__(self, custom_retriever: CustomRetriever, k=5):
        super().__init__()
        self.retriever_wrapper = DSPyRetrieverWrapper(custom_retriever)
        self.generate = dspy.ChainOfThought(CustomRAGSignature)
        self.k = k

    def forward(self, question: str):
        # Retrieve using custom retriever
        retrieved = self.retriever_wrapper(question, k=self.k)
        context = "\\n\\n".join(retrieved.passages)

        # Generate answer
        result = self.generate(context=context, question=question)
        return result


# ============================================================================
# 6. USAGE EXAMPLE
# ============================================================================

def main():
    """Example usage of custom retriever."""

    # Sample documents
    documents = [
        {"text": "DSPy is a framework for programming with foundation models.", "id": 1},
        {"text": "ColBERTv2 provides state-of-the-art neural retrieval.", "id": 2},
        {"text": "RAG combines retrieval with generation for better answers.", "id": 3},
    ]

    # Create custom retriever
    retriever = KeywordRetriever(documents)

    # Create RAG module
    rag = CustomRAGModule(retriever, k=2)

    # Use it
    question = "What is DSPy?"
    result = rag(question=question)

    print(f"Q: {question}")
    print(f"A: {result.answer}")


# ============================================================================
# 7. ADVANCED: DOMAIN-SPECIFIC RETRIEVER
# ============================================================================

class DomainSpecificRetriever(CustomRetriever):
    """Example: Domain-specific retriever with business logic."""

    def __init__(self, documents: List[Dict[str, Any]], domain_rules: Dict):
        self.documents = documents
        self.domain_rules = domain_rules

    def __call__(self, query: str, k: int = 5) -> List[Dict[str, Any]]:
        """Retrieve with domain-specific logic."""
        # Apply domain-specific filtering
        filtered_docs = self._apply_domain_filters(query)

        # Score and rank
        scored = self._score_documents(query, filtered_docs)

        # Return top k
        return [doc for _, doc in sorted(scored, reverse=True)[:k]]

    def _apply_domain_filters(self, query: str) -> List[Dict[str, Any]]:
        """Apply domain-specific filtering rules."""
        # Example: Filter by date, category, etc.
        return self.documents

    def _score_documents(self, query: str, docs: List[Dict]) -> List[tuple]:
        """Score documents based on domain-specific criteria."""
        # Implement your scoring logic
        return [(1.0, doc) for doc in docs]


if __name__ == "__main__":
    main()
'''

    def _generate_embeddings(self, use_case: str = "rag") -> str:
        """Generate embeddings-based retriever template."""
        return '''"""
Embeddings-Based Retriever

Vector-based retrieval using embeddings and vector databases.

Generated by RLM Code - Retriever Template
"""

import dspy
from typing import List, Dict, Any
import numpy as np


# ============================================================================
# 1. CONFIGURE EMBEDDING MODEL
# ============================================================================

# Option 1: Use DSPy's Embeddings retriever
try:
    from dspy.retrievers import Embeddings
    embedding_retriever = Embeddings()
    print("✓ Using DSPy Embeddings retriever")
except ImportError:
    print("⚠️  DSPy Embeddings not available, using custom implementation")
    embedding_retriever = None

# Option 2: Use sentence-transformers
try:
    from sentence_transformers import SentenceTransformer
    embedding_model = SentenceTransformer('all-MiniLM-L6-v2')
    print("✓ Using sentence-transformers")
except ImportError:
    print("⚠️  sentence-transformers not installed")
    embedding_model = None


# ============================================================================
# 2. VECTOR DATABASE SETUP
# ============================================================================

# Option 1: FAISS (Facebook AI Similarity Search)
try:
    import faiss
    use_faiss = True
    print("✓ FAISS available")
except ImportError:
    use_faiss = False
    print("⚠️  FAISS not installed: pip install faiss-cpu")

# Option 2: Chroma
try:
    import chromadb
    use_chroma = True
    print("✓ Chroma available")
except ImportError:
    use_chroma = False
    print("⚠️  Chroma not installed: pip install chromadb")


# ============================================================================
# 3. EMBEDDING RETRIEVER WITH FAISS
# ============================================================================

class FAISSRetriever:
    """FAISS-based vector retriever."""

    def __init__(self, documents: List[str], embedding_model=None):
        """
        Initialize FAISS retriever.

        Args:
            documents: List of document texts
            embedding_model: Embedding model (default: sentence-transformers)
        """
        self.documents = documents

        if embedding_model is None:
            from sentence_transformers import SentenceTransformer
            self.embedding_model = SentenceTransformer('all-MiniLM-L6-v2')
        else:
            self.embedding_model = embedding_model

        # Generate embeddings
        print(f"Generating embeddings for {len(documents)} documents...")
        embeddings = self.embedding_model.encode(documents)

        # Create FAISS index
        dimension = embeddings.shape[1]
        self.index = faiss.IndexFlatL2(dimension)
        self.index.add(embeddings.astype('float32'))

        print(f"✓ Created FAISS index with {self.index.ntotal} vectors")

    def __call__(self, query: str, k: int = 5) -> List[Dict[str, Any]]:
        """Retrieve documents for query."""
        # Embed query
        query_embedding = self.embedding_model.encode([query])

        # Search in FAISS
        distances, indices = self.index.search(query_embedding.astype('float32'), k)

        # Return results
        results = []
        for idx, dist in zip(indices[0], distances[0]):
            if idx < len(self.documents):
                results.append({
                    "text": self.documents[idx],
                    "score": float(dist),
                    "index": int(idx)
                })

        return results


# ============================================================================
# 4. EMBEDDING RETRIEVER WITH CHROMA
# ============================================================================

class ChromaRetriever:
    """Chroma-based vector retriever."""

    def __init__(self, documents: List[Dict[str, Any]], collection_name="documents"):
        """
        Initialize Chroma retriever.

        Args:
            documents: List of dicts with 'text' and optional 'id', 'metadata'
            collection_name: Chroma collection name
        """
        import chromadb
        from chromadb.config import Settings

        # Initialize Chroma client
        self.client = chromadb.Client(Settings(
            chroma_db_impl="duckdb+parquet",
            persist_directory="./chroma_db"
        ))

        # Create or get collection
        self.collection = self.client.get_or_create_collection(
            name=collection_name,
            metadata={"hnsw:space": "cosine"}
        )

        # Add documents if collection is empty
        if self.collection.count() == 0:
            texts = [doc.get('text', '') for doc in documents]
            ids = [doc.get('id', str(i)) for i, doc in enumerate(documents)]
            metadatas = [doc.get('metadata', {}) for doc in documents]

            self.collection.add(
                documents=texts,
                ids=ids,
                metadatas=metadatas
            )
            print(f"✓ Added {len(documents)} documents to Chroma")
        else:
            print(f"✓ Using existing Chroma collection with {self.collection.count()} documents")

    def __call__(self, query: str, k: int = 5) -> List[Dict[str, Any]]:
        """Retrieve documents for query."""
        results = self.collection.query(
            query_texts=[query],
            n_results=k
        )

        # Format results
        retrieved = []
        if results['documents']:
            for i, doc in enumerate(results['documents'][0]):
                retrieved.append({
                    "text": doc,
                    "id": results['ids'][0][i] if results['ids'] else None,
                    "metadata": results['metadatas'][0][i] if results['metadatas'] else {},
                    "distance": results['distances'][0][i] if results['distances'] else None
                })

        return retrieved


# ============================================================================
# 5. RAG MODULE WITH EMBEDDINGS RETRIEVER
# ============================================================================

class EmbeddingRAGSignature(dspy.Signature):
    """Answer questions using embedding-retrieved context."""
    context = dspy.InputField(desc="Retrieved context passages")
    question = dspy.InputField(desc="User's question")
    answer = dspy.OutputField(desc="Answer based on context")


class EmbeddingRAGModule(dspy.Module):
    """RAG system using embeddings-based retrieval."""

    def __init__(self, retriever, k=5):
        super().__init__()
        self.retriever = retriever
        self.generate = dspy.ChainOfThought(EmbeddingRAGSignature)
        self.k = k

    def forward(self, question: str):
        # Retrieve using embeddings
        results = self.retriever(question, k=self.k)
        context = "\\n\\n".join([r.get('text', '') for r in results])

        # Generate answer
        result = self.generate(context=context, question=question)
        return result


# ============================================================================
# 6. USAGE EXAMPLES
# ============================================================================

def example_faiss():
    """Example using FAISS."""
    documents = [
        "DSPy is a framework for programming with foundation models.",
        "ColBERTv2 provides neural retrieval capabilities.",
        "RAG combines retrieval with generation.",
    ]

    retriever = FAISSRetriever(documents)
    rag = EmbeddingRAGModule(retriever, k=2)

    result = rag(question="What is DSPy?")
    print(f"Answer: {result.answer}")


def example_chroma():
    """Example using Chroma."""
    documents = [
        {"text": "DSPy is a framework...", "id": "doc1", "metadata": {"source": "docs"}},
        {"text": "ColBERTv2 provides...", "id": "doc2", "metadata": {"source": "docs"}},
    ]

    retriever = ChromaRetriever(documents)
    rag = EmbeddingRAGModule(retriever, k=2)

    result = rag(question="What is DSPy?")
    print(f"Answer: {result.answer}")


# ============================================================================
# 7. BENEFITS OF EMBEDDINGS RETRIEVAL
# ============================================================================

"""
Benefits:
- Semantic understanding (not just keywords)
- Works with vector databases (FAISS, Chroma, Pinecone)
- Fast similarity search
- Scalable to large document collections
- Can combine with metadata filtering
"""

if __name__ == "__main__":
    if use_faiss:
        example_faiss()
    elif use_chroma:
        example_chroma()
    else:
        print("Install FAISS or Chroma to use embeddings retrieval")
'''
