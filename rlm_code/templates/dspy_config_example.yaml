# RLM Code Configuration Example
# This file shows all available configuration options for RLM Code
# Copy sections you need to your dspy_config.yaml file

# ============================================================================
# PROJECT INFORMATION
# ============================================================================
name: my-dspy-project
version: 0.1.0
dspy_version: 2.4.0

# ============================================================================
# OUTPUT CONFIGURATION
# ============================================================================
# Directory where generated DSPy components will be saved
output_directory: generated

# ============================================================================
# MODEL CONFIGURATION
# ============================================================================
# Configure language models for DSPy programs
# You can use local models (Ollama) or cloud providers (OpenAI, Anthropic, Gemini)

models:
  # --- Ollama (Local Models) ---
  # Free, private, runs on your machine
  ollama_endpoint: http://localhost:11434
  ollama_models:
    - llama2
    - mistral
    - codellama

  # --- OpenAI ---
  # Requires API key from https://platform.openai.com/api-keys
  # RECOMMENDED: Set OPENAI_API_KEY environment variable or in .env file
  # DO NOT commit API keys to version control!
  openai_api_key: null  # Leave as null to use environment variable OPENAI_API_KEY
  openai_model: gpt-5.3-codex  # Options: gpt-5.3-codex, gpt-5.2-pro, gpt-4o

  # --- Anthropic Claude ---
  # Requires API key from https://console.anthropic.com/
  # RECOMMENDED: Set ANTHROPIC_API_KEY environment variable or in .env file
  anthropic_api_key: null  # Leave as null to use environment variable ANTHROPIC_API_KEY
  anthropic_model: claude-opus-4-6  # Options: claude-opus-4-6, claude-sonnet-4-5-20250929, claude-haiku-4-5-20251001

  # --- Google Gemini ---
  # Requires API key from https://aistudio.google.com/apikey
  # RECOMMENDED: Set GEMINI_API_KEY or GOOGLE_API_KEY environment variable or in .env file
  gemini_api_key: null  # Leave as null to use environment variable GEMINI_API_KEY
  gemini_model: gemini-2.5-flash  # Options: gemini-2.5-pro, gemini-2.5-flash, gemini-2.0-flash

  # --- Reflection Model (for GEPA Optimization) ---
  # Model used for reflection during GEPA optimization
  # If not set, uses default_model
  # Recommended: Use a strong model (gpt-4, claude-3-opus) for best optimization results
  reflection_model: null  # e.g., "gpt-4", "claude-3-opus", "ollama/llama3.2:70b"

# Default model to use when not specified
# Format: model name (e.g., "gpt-4", "llama2") or provider/model (e.g., "openai/gpt-4", "ollama/llama2")
default_model: null

# ============================================================================
# SANDBOX CONFIGURATION
# ============================================================================
# Configure runtime used by /run and /test commands

sandbox:
  # Runtime backend: local | docker | apple-container
  runtime: local
  # Preset policy: secure | dev | custom
  superbox_profile: custom
  # Enable automatic runtime fallback chain
  superbox_auto_fallback: true
  # Ordered fallback candidates used by superbox
  superbox_fallback_runtimes:
    - docker
    - apple-container
    - local

  # Default timeout for execution commands (seconds)
  default_timeout_seconds: 30

  # Default memory limit (MB) for sandbox policies
  memory_limit_mb: 512

  # Host roots allowed for container bind mounts
  # Relative paths are resolved from project root.
  allowed_mount_roots:
    - .
    - /tmp
    - /var/folders

  # Host environment variables to pass through into sandbox execution
  # Keep this small and explicit.
  env_allowlist: []

  # Enable experimental Apple container runtime
  apple_container_enabled: false

  # Pure RLM secure backend preference: docker | monty | exec (unsafe opt-in)
  pure_rlm_backend: docker
  pure_rlm_allow_unsafe_exec: false
  pure_rlm_strict: false
  pure_rlm_output_mode: summarize
  pure_rlm_max_iteration_output_chars: 12000
  monty_type_check: false
  monty_max_allocations: null
  monty_max_memory: null

  docker:
    # Docker image used for isolated Python execution
    image: python:3.11-slim
    memory_limit_mb: 512
    cpus: 1.0
    network_enabled: false
    extra_args: []

# ============================================================================
# RLM CONFIGURATION
# ============================================================================
# Configure /rlm behavior, benchmark defaults, and reward shaping.

rlm:
  # Default preset used by /rlm bench when preset is omitted
  default_benchmark_preset: dspy_quick

  # Optional benchmark pack YAML files (relative to project root or absolute).
  # These add/override presets used by /rlm bench.
  benchmark_pack_paths: []
  # Example:
  # benchmark_pack_paths:
  #   - rlm_benchmarks.yaml
  #   - benchmarks/dspy_release_gate.yaml
  # See template: rlm_code/templates/rlm_benchmarks_example.yaml

  # Reward shaping controls for RLM environments.
  # Values below are defaults that preserve current behavior.
  reward:
    global_scale: 1.0
    run_python_base: 0.1
    run_python_success_bonus: 0.7
    run_python_failure_penalty: 0.3
    run_python_stderr_penalty: 0.1
    dspy_pattern_match_bonus: 0.03
    dspy_pattern_bonus_cap: 0.2
    verifier_base: 0.15
    verifier_score_weight: 0.5
    verifier_compile_bonus: 0.2
    verifier_compile_penalty: 0.35
    verifier_pytest_bonus: 0.25
    verifier_pytest_penalty: 0.25
    verifier_validation_bonus: 0.15
    verifier_validation_penalty: 0.3
    verifier_warning_penalty_per_warning: 0.03
    verifier_warning_penalty_cap: 0.15

# ============================================================================
# OPTIMIZATION CONFIGURATION (GEPA)
# ============================================================================
# Configure the GEPA (Genetic Pareto) optimizer
# Used when running: rlm-code optimize

gepa_config:
  # Maximum number of optimization iterations
  max_iterations: 10

  # Population size for genetic algorithm
  # Larger = more diverse but slower
  population_size: 20

  # Mutation rate (0.0 to 1.0)
  # Higher = more exploration, lower = more exploitation
  mutation_rate: 0.1

  # Crossover rate (0.0 to 1.0)
  # Probability of combining two solutions
  crossover_rate: 0.8

  # Evaluation metric for optimization
  # Options: accuracy, f1, precision, recall, custom
  evaluation_metric: accuracy

# ============================================================================
# DSPY OPTIMIZER CONFIGURATION
# ============================================================================
# Additional DSPy optimizer settings (beyond GEPA)

optimizer:
  # Optimizer type
  # Options: BootstrapFewShot, MIPRO, COPRO, SignatureOptimizer
  type: BootstrapFewShot

  # Number of bootstrap examples
  max_bootstrapped_demos: 4

  # Maximum number of labeled examples to use
  max_labeled_demos: 16

  # Teacher model for bootstrapping (if different from default)
  teacher_model: null

  # Metric function for evaluation
  # Can be: accuracy, f1_score, exact_match, or custom function name
  metric: accuracy

  # Number of threads for parallel optimization
  num_threads: 4

# ============================================================================
# EVALUATION METRICS
# ============================================================================
# Configure evaluation metrics for your DSPy programs

evaluation:
  # Default metrics to compute
  metrics:
    - accuracy
    - f1_score
    - precision
    - recall

  # Custom metric functions (Python module paths)
  custom_metrics:
    # Example: my_metrics.custom_accuracy
    # - module.function_name

  # Validation split ratio (0.0 to 1.0)
  validation_split: 0.2

  # Test split ratio (0.0 to 1.0)
  test_split: 0.1

  # Random seed for reproducibility
  random_seed: 42

# ============================================================================
# SIGNATURE CONFIGURATION
# ============================================================================
# Configure DSPy signature generation preferences

signatures:
  # Default signature style
  # Options: concise, detailed, minimal
  style: concise

  # Include type hints in signatures
  include_types: true

  # Include descriptions in signatures
  include_descriptions: true

  # Maximum number of input fields
  max_input_fields: 5

  # Maximum number of output fields
  max_output_fields: 3

# ============================================================================
# REASONING PATTERNS
# ============================================================================
# Configure reasoning pattern preferences

reasoning:
  # Default reasoning pattern
  # Options: predict, chain_of_thought, react, program_of_thought
  default_pattern: chain_of_thought

  # Chain of Thought settings
  cot:
    # Number of reasoning steps
    max_steps: 5

    # Include intermediate reasoning in output
    show_reasoning: true

  # ReAct settings
  react:
    # Maximum number of actions
    max_actions: 10

    # Available tools/actions
    tools: []

  # Program of Thought settings
  pot:
    # Enable code execution
    enable_execution: false

    # Execution timeout (seconds)
    timeout: 30

# ============================================================================
# TEMPLATE PREFERENCES
# ============================================================================
# Customize code generation templates

template_preferences:
  # Code style
  # Options: functional, class-based, modular
  code_style: class-based

  # Include docstrings
  include_docstrings: true

  # Include type hints
  include_type_hints: true

  # Include example usage
  include_examples: true

  # Formatting style
  # Options: black, pep8, google
  formatting_style: black

# ============================================================================
# LOGGING AND DEBUGGING
# ============================================================================
# Configure logging and debugging options

logging:
  # Log level
  # Options: DEBUG, INFO, WARNING, ERROR, CRITICAL
  level: INFO

  # Log file path (null for console only)
  file: null

  # Include timestamps
  include_timestamps: true

  # Log DSPy internal operations
  log_dspy_internals: false

# ============================================================================
# CACHING
# ============================================================================
# Configure caching for model responses and computations

caching:
  # Enable caching
  enabled: true

  # Cache directory
  cache_dir: .dspy_cache

  # Cache expiration (seconds, null for no expiration)
  expiration: null

  # Maximum cache size (MB)
  max_size: 1000

# ============================================================================
# RETRIEVAL CONFIGURATION
# ============================================================================
# Configure retrieval models for RAG (Retrieval-Augmented Generation)

retrieval:
  # Retrieval model type
  # Options: colbertv2, sentence-transformers, openai-embeddings
  model_type: colbertv2

  # Model name/path
  model_name: colbertv2.0

  # Number of documents to retrieve
  k: 5

  # Vector database
  # Options: faiss, chroma, pinecone, weaviate
  vector_db: faiss

  # Vector database configuration
  vector_db_config:
    # Database path or connection string
    path: .vector_db

    # Embedding dimension
    dimension: 768

# ============================================================================
# MCP (Model Context Protocol) SERVERS
# ============================================================================
# Configure external MCP servers for additional capabilities

mcp_servers:
  # Example: Filesystem server
  # filesystem:
  #   command: npx
  #   args:
  #     - -y
  #     - "@modelcontextprotocol/server-filesystem"
  #     - /path/to/allowed/directory
  #   env:
  #     NODE_ENV: production

  # Example: GitHub server
  # github:
  #   command: npx
  #   args:
  #     - -y
  #     - "@modelcontextprotocol/server-github"
  #   env:
  #     GITHUB_TOKEN: your_token_here

# ============================================================================
# ADVANCED SETTINGS
# ============================================================================

advanced:
  # Enable experimental features
  experimental_features: false

  # Maximum retries for API calls
  max_retries: 3

  # Timeout for API calls (seconds)
  api_timeout: 60

  # Enable parallel processing
  parallel_processing: true

  # Number of parallel workers
  num_workers: 4

  # Memory limit per worker (MB)
  memory_limit: 2048

# ============================================================================
# DATASET CONFIGURATION
# ============================================================================

datasets:
  # Default dataset format
  # Options: jsonl, csv, parquet, huggingface
  default_format: jsonl

  # Dataset directory
  data_dir: data

  # Training data path
  train_path: null

  # Validation data path
  val_path: null

  # Test data path
  test_path: null

  # Automatic dataset splitting
  auto_split: true

# ============================================================================
# EXPORT CONFIGURATION
# ============================================================================

export:
  # Default export format
  # Options: python, json, package
  default_format: python

  # Include configuration in exports
  include_config: true

  # Include dependencies
  include_dependencies: true

  # Export directory
  export_dir: exports

# ============================================================================
# ENVIRONMENT VARIABLES & API KEYS
# ============================================================================
# BEST PRACTICE: Store API keys in environment variables or .env file
#
# Create a .env file in your project root (automatically loaded):
#   OPENAI_API_KEY=sk-...
#   ANTHROPIC_API_KEY=sk-ant-...
#   GEMINI_API_KEY=...
#
# Or set environment variables:
#   export OPENAI_API_KEY=sk-...
#   export ANTHROPIC_API_KEY=sk-ant-...
#
# The .env file should be in .gitignore to prevent committing secrets!
#
# Priority order:
#   1. Environment variables (highest priority)
#   2. .env file
#   3. Values in this config file (not recommended for API keys)

# ============================================================================
# NOTES
# ============================================================================
# - API keys should be set as environment variables (see above)
# - Use null for optional fields you don't want to configure
# - See documentation for more details: https://dspy-docs.vercel.app/
# - NEVER commit API keys to version control!
# - Add .env to your .gitignore file
